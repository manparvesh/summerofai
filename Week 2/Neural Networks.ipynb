{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "\n",
    "- NNs are function approximators that take tensors as input and give tensors as output.\n",
    "- Output will be the best guess of an answer\n",
    "- We need to train a network first by using the steps below, and then use it.\n",
    "- Input shapes need to be specified before using the network\n",
    "\n",
    "## Network training lifecycle\n",
    "\n",
    "1. Gathering the data\n",
    "2. Defining the network architecture\n",
    "3. Training the network using a loop\n",
    "\n",
    "## Fully connected NN\n",
    "\n",
    "- Consists of nodes (neurons)\n",
    "- Nodes are stacked in layers\n",
    "- All nodes in a layer are connected to all nodes in the next layer\n",
    "- Internal layers are called hidden layers since we don't observe them\n",
    "\n",
    "## Neuron\n",
    "\n",
    "- Tiny bit of computation\n",
    "- kind of like `if` statements chained together\n",
    "- will have multiple inputs and single output\n",
    "\n",
    "### Components\n",
    "\n",
    "- combines all inputs\n",
    "- shift them up or down\n",
    "- has a switch (activation function) that decides whether or not to pass that value on\n",
    "\n",
    "### Mathematical computation inside neurons\n",
    "\n",
    "- A neuron decides how much attention to give to each input using a parameter called `weight`\n",
    "  - positive weight would be to emphasise a value\n",
    "  - zero weight means ignore that value\n",
    "  - negative weight means to use the opposite of that value\n",
    "- Values are combined using simple addition\n",
    "- This value is then shifted using `bias` which can also be +ve, 0, -ve\n",
    "- Activation: pass if meets the condition, else pass 0. usually the check used is if the value is +ve or not.\n",
    "- While training, we keep adjusting `weight` and `biases` inside neurons for better results\n",
    "\n",
    "## Training process\n",
    "\n",
    "- Show input data: provide the network with training data\n",
    "- Calculate loss: calculate how wrong the network was. there are different loss functions\n",
    "- Back propagation: \n",
    "  - tell the network to take that loss and propagate it back towards the network so that each neuron can know how much it contibutes to the overall bad guess, and in which direction it needs to shift in order to get closer to the right answer. \n",
    "  - Possible due to special feature of tensors. \n",
    "  - each tensor has a component called the `gradient` \n",
    "  - when final loss is calculated, these gradients are used to figure out how to update all the weights and biases to be more correct.\n",
    "- update weights and biases based on the calculations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Summer of AI)",
   "language": "python",
   "name": "summerofai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
